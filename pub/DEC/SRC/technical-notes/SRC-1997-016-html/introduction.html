<HTML>
<HEAD>
<TITLE>
1. Introduction - Continuous Profiling: Where Have All the Cycles Gone?
</TITLE>
</HEAD>

<BODY>

<H1>
<CENTER>
<A HREF="sosp97.html">Continuous Profiling: Where Have All the Cycles Gone?</A>
<P>
1. Introduction
</CENTER>
</H1>

<P>
The performance of programs running on modern high-performance
computer systems is often hard to understand.  Processor pipelines are
complex, and memory system effects have a significant impact on
performance.  When a single program or an entire system does not
perform as well as desired or expected, it can be difficult to
pinpoint the reasons.  The DIGITAL Continuous Profiling Infrastructure
provides an efficient and accurate way of answering such questions.
</P>

<P>
The system consists of two parts, each with novel features: a data
collection subsystem that samples program counters and records them in
an on-disk database, and a suite of analysis tools that analyze the
stored profile information at several levels, from the fraction of CPU
time consumed by each program to the number of stall cycles for each
individual instruction.  The information produced by the analysis
tools guides users to time-critical sections of code and explains in
detail the static and dynamic delays incurred by each instruction.
</P>

<P>
We faced two major challenges in designing and implementing our
profiling system: efficient data collection for a very high sampling
rate, and the identification and classification of processor stalls
from program-counter samples.  The data collection system uses
periodic interrupts generated by performance counters available on
DIGITAL Alpha processors to sample program counter values.  (Other
processors, such as Intel's Pentium Pro and SGI's R10K, also have
similar hardware support.)  Profiles are collected for unmodified
executables, and all code is profiled, including applications, shared
libraries, device drivers, and the kernel.  Thousands of samples are
gathered each second, allowing useful profiles to be gathered in a
relatively short time.  Profiling is also efficient: overhead is about
1-3% of the processor time, depending on the workload.  This
permits the profiling system to be run continuously on production
systems and improves the quality of the profiles by minimizing the
perturbation of the system induced by profiling.
</P>

<P>
The collected profiles contain time-biased samples of program counter
values: the number of samples associated with a particular program
counter value is proportional to the total time spent executing that
instruction.  Samples that show the relative number of cache misses,
branch mispredictions, etc. incurred by individual instructions are
also collected.
</P>

<P>
Some of the analysis tools use the collected samples to generate the
usual histograms of time spent per image, per procedure, per source
line, or per instruction.  Other analysis tools use a detailed machine
model and heuristics described in
<A HREF="analysis.html">Section 6</A>
to convert time-biased samples into the average number of cycles spent
executing each instruction, the number of times each instruction was
executed, and explanations for any static or dynamic stalls.
</P>

<P>
<A HREF="examples.html">Section 3</A>
contains several
examples of the output
from our tools.  As discussed there, the combination of fine-grained
instruction-level analysis and detailed profiling of long-running
workloads has produced insights into performance that are difficult to
achieve with other tools.  These insights have been used to improve
the performance of several major commercial applications.
</P>

<P>
The output of the analysis tools can be used directly by programmers;
it can also be fed into compilers, linkers, post-linkers, and run-time
optimization tools.  The profiling system is freely available on the
Web at
<A HREF="http://www.research.digital.com/SRC/dcpi">
http://www.research.digital.com/SRC/dcpi</A>;
it has been running on DIGITAL Alpha processors
under DIGITAL Unix since September 1996, and ports are in progress
to Alpha/NT and OpenVMS.  Work is underway to feed the output of our
tools into DIGITAL's optimizing 
backend<A HREF="references.html#Bli92">[Bli92]</A>
and into the
Spike/OM post-linker optimization 
framework<A HREF="references.html#CohL96">[CohL96]</A>
<A HREF="references.html#CohGLR97">[CohGLR97]</A>.
We are also studying new kinds of profile-driven optimizations made
possible by the fine-grained instruction-level profile information
provided by our system.
</P>

<P>
<A HREF="related.html">Section 2</A>
discusses other profiling systems.
<A HREF="examples.html">Section 3</A>
illustrates the use of our system.
<A HREF="collection.html">Section 4</A>
and
<A HREF="collection-performance.html">Section 5</A>
describe the
design and performance of our data collection system,
highlighting the techniques used to achieve low overhead with
a high sampling rate.
<A HREF="analysis.html">Section 6</A>
describes the subtle and interesting
techniques used in our analysis tools, explaining
how to derive each instruction's CPI, execution frequency, and
explanations for stalls from the raw sample counts.
Finally,
<A HREF="future.html">Section 7</A>
discusses future work
and
<A HREF="conclusions.html">Section 8</A>
summarizes our results.
</P>
<HR>

<BLOCKQUOTE>
<A HREF="sosp97.html"> Beginning of paper </A> <BR>
<A HREF="abstract.html">Abstract</A> <BR>
1. Introduction <BR>
<A HREF="related.html">2. Related Work</A> <BR>
<A HREF="examples.html">3. Data Analysis Examples</A> <BR>
<A HREF="collection.html">4. Data Collection System</A> <BR>
<A HREF="collection-performance.html">5. Profiling Performance</A> <BR>
<A HREF="analysis.html">6. Data Analysis Overview</A> <BR>
<A HREF="future.html">7. Future Directions</A> <BR>
<A HREF="conclusions.html">8. Conclusions</A> <BR>
<A HREF="acks.html">Acknowledgements</A> <BR>
<A HREF="references.html">References</A>
</BLOCKQUOTE>

<HR>

This paper was published in the Proceedings of the 16th ACM Symposium
on Operating Systems Principles, October, 1997. Copyright 1997 by the
Assocation for Computing Machinery. All rights reserved. Republished
by permission.

</BODY>
</HTML>
