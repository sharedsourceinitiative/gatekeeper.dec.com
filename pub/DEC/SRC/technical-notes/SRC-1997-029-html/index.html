<HTML>

<HEAD>
   <TITLE>SRC Technical Note 1997-029</TITLE>
   <META NAME="AUTHOR" CONTENT="Thomas Kistler and Hannes Marais">
</HEAD>

<BODY BGCOLOR="#FFFFFF">
<HR>
<CENTER>
<H2><B>SRC Technical Note</B></H2><P>
<H3><B>1997-029</B></H3><P>
<H3>December 1, 1997</H3><P>
<HR>
<H2>WebL &#150 A Programming Language for the Web</H2>
<P><br>
<H3>Thomas Kistler&sup1; and Hannes Marais&sup2;</H3>
&sup1; Information and Computer Science Department, <br>
University of California at Irvine<br>
E-mail: <a href="mailto:kistler@ics.uci.edu">kistler@ics.uci.edu</a><br>
<br>
&sup2; DIGITAL Systems Research Center<br>
E-mail: <a href="mailto:marais@pa.dec.com">marais@pa.dec.com</a><br>
<br><br><br>
<HR>
<p>

<IMG SRC="http://www.research.digital.com/SRC/pics/DEC-logo.gif"
ALT="DIGITAL"><BR>
<B>Systems Research Center</B><BR>
130 Lytton Avenue<BR>
Palo Alto, CA 94301<BR>
<A HREF="http://www.research.digital.com/SRC/">http://www.research.digital.com/SRC/</A>
<P>

<HR>
&copy; Copyright 1997 Digital Equipment Corporation. All rights reserved
<HR>
</CENTER>


<CENTER>
<H3>Abstract</H3></CENTER>

<BLOCKQUOTE><I>In this paper we introduce a programming language for Web
document processing called WebL. WebL is a high level, object-oriented
scripting language that incorporates two novel features: service combinators
and a markup algebra. Service combinators are language constructs that
provide reliable access to web services by mimicking a web surfer's behavior
when a failure occurs while retrieving a page. The markup algebra extracts
structured and unstructured values from pages for computation, and is based
on algebraic operations on sets of markup elements. WebL is used to quickly
build and experiment with custom web crawlers, meta-search engines, page
transducers, shopping robots, etc.</I></BLOCKQUOTE>

<H2>1. A Computation Model for the Web</H2>

The architectural, physical and administrative constraints of the Internet require new 
models for computing over planet-wide structures such as the World-Wide-Web. 

Some of the characteristics of the web, like its wide area distribution,
unreliable services, lack of referential integrity, security model,
and lack of data typing, differ immensely from those of traditional
programming models, which presupposes a non-distributed, well-structured,
and predictable infrastructure. 

Furthermore, because of the web's geographical
distribution, latency and bandwidth &#150; not CPU speed and memory size &#150;
become the limiting factors that need to be addressed. So what
kind of programming models and programming constructs are needed to compute
on the web? To understand this question, we first have to study typical
web computations. In our view, a typical web computation can be divided into three
phases.

<P><I>The input phase</I> involves fetching one or more web pages
for processing. During this phase we have to contend with the web's geographic
distribution and architectural inefficiencies. For example, one or more
of the following situations might apply when retrieving a page from a web service:

<UL>
<LI>The page is available and can be retrieved successfully.</LI>

<LI>The server is unavailable or provides intermittent
service due to a high load.</LI>

<LI>The page is (perhaps temporarily) unavailable or was redirected to another server.</LI>

<LI>The connection is unexpectedly terminated or the data transfer speed varies, stalling or dropping to an unacceptable rate.</LI>

<LI>The page is mirrored geographically, perhaps on servers with different
capacity.</LI>

</UL>

Consequently, a programming model for the web not only has to expect several modes
of failure (for which many programs are typically not designed) but should also
provide functionality to overcome these problems, for example, to exploit 
the inherent paralellism of replicated
servers. Our approach is to use <I>service
combinators</I> to make access to services more reliable and to simplify
the handling of failures (see section 3).

<P><I>The processing phase</I> of a typical web computation involves
extracting data values from pages and performing computations on these
data values. We assume pages to be marked-up in either XML or HTML, so
as to exploit the structural content of the page. Our data extraction
technique is based on a <I>markup algebra</I> that performs operations on sets of
elements in a page (see section 4).

<P><I>The output phase</I> of a typical web computation covers the generation
of web documents from values computed during the processing phase, and
storing them back on the web (for example, by publishing the page on a web server).

<P><i>Figure 1</i> depicts this general model of a web computation. Web pages
flow through a pipeline of service combinators for fetching pages,
a markup parser, the markup algebra for extracting (or "searching" for) data values from (on) a page,
computing on those values, and page manipulation. Searching, computing and manipulation is repeated as often as needed.
Finally the page is regenerated from its internal representation by the markup generator, and stored back on the web.

<CENTER><IMG SRC="model.gif" ></CENTER>

<CENTER><I>Figure 1.</I>A Model for Computation on the Web</CENTER>

<H2>2. The Programming Language WebL</H2>

Our implementation of this computation model is called <i>WebL</i>.
WebL is a high level, dynamically typed, object oriented scripting language
that was specifically designed for performing web computations. It
incorporates two novel features: <i>service combinators</i> and a <i>markup algebra</i>. WebL also provides
functionality to generate new web pages or to modify existing ones, and
provides special modules to simplify web-related tasks. Besides the features
that are tailored towards manipulating HTML and XML, the language supports
modules, closures, exceptions, sets, lists, associative arrays, multithreading,
built-in load balancing, and channel-based synchronization. These features
make WebL a convenient language to prototype computations on the web and
an excellent tool for web masters. WebL's syntax
is a mix of C, C++, Modula-2 [Wir82], and Obliq [Car94]. 
Even though we incorporated many features
into the language, we believe WebL is still simple and easy to learn.

<P>Some of the applications we constructed with WebL so far include:

<UL>
<LI>Customizable web crawlers</LI>

<LI>Meta-search engines for popular search engines on the web</LI>

<LI>Meta-newspapers that collect articles from several sites according to
your interests</LI>

<LI>Tools to build a newspaper from CDF-based descriptions [CDF97]</LI>

<LI>Shopping robots that shop for the cheapest books at several electronic
bookstores</LI>

<LI>Tools to extract financial information from stock pages</LI>

<LI>Tools to extract and compute project information from DIGITAL's intranet</LI>

<LI>Tools to concatenate Latex2HTML-generated documents for printing</LI>

<LI>Tools to validate links in web pages</LI>
</UL>

The WebL prototype is implemented in pure Java. To complement writing WebL programs,
WebL functions are also directly accessible from within Java code. This assists programmers 
that want to use the WebL functionality, but
don't want to learn yet another programming language. This mixed approach also
allowed us to easily extend WebL with support for existing Java APIs, for example libraries that
implement web-servers and libraries to access relational databases.

<P>In the remainder of the paper we will concentrate on the two novel aspects
of WebL, namely service combinators (section 3) and the markup algebra
(section 4). These sections are followed with related work (section 5)
and conclusions (section 6). An appendix lists example programs.

<h2>3. Service Combinators</H2>

An experienced web surfer exploits a repertoire of behaviors when confronted
with the situations introduced in section 1 (e.g. server failure,
stalling or dropping service rates, etc.). We call these behaviors <I>web
reflexes</I>. For example, users may

<UL>
<LI>reload a page on a stalled link</LI>

<LI>retry requests, taking short pauses in between requests</LI>

<LI>terminate a request that takes too long</LI>

<LI>switch to less used servers with the same information</LI>

<LI>switch to alternate sources of information</LI>

<LI>monitor the transfer rate and decide whether to wait for the page to
arrive</LI>

<LI>run fetches in parallel, waiting for the first to finish, and stopping
the other requests</LI>
</UL>

A strategy for making computations on the web more reliable is to use programming
constructs called <I>service combinators </I>[CD97]<I>.</I> The main purpose
of service combinators is to mimic these reflexes or, in a more general
way, to make any algorithmic behavior of web users scriptable. Therefore,
under the basic premise that by providing the programmer with easier ways to
express these reflexes and it becomes easier to write robust scripts, service
combinators provide explicit language constructs to automate handling of
time-out and failure, exploitation of replicated data, etc. As in the approach
suggested in [CD97], WebL maps service combinators directly onto operators
of the language. As will be noticed from the following examples, service
combinators are also convenient language constructs for handling exceptions.

<P>For the remainder of this section <I>S </I>and <I>T </I>to denote operands
(called <I>services</I>), which may contain primitives to fetch pages or
general WebL computations.

<P>&nbsp;&nbsp;&nbsp; <I>Services</I>
<UL><TT>getpage(string, [. param1=val1, param2=val2, ... .],</TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [. header1=val1, header2=val2
.])</TT>
<BR><TT>postpage(string, [. param1=val1, param2=val2, ... .],</TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [. header1=val1, header2=val2
.])</TT>

<P>The <I>getpage</I> function fetches with the HTTP GET protocol the resource
associated with the string URL. The result returned is a page object that
encapsulates the resource. The function fails if the fetch fails. The second
and third arguments to getpage are optional &#150; when specified, they provide
the server with query arguments and HTTP headers
respectively. A similar function called <I>postpage</I> uses the HTTP POST
protocol, used to fill in web-based input forms.<p>

<UL><TT>// This program simply attempts to fetch the named URL.</TT>
<BR><TT>page := getpage("http://www.digital.com")</TT>

<P><TT>// This program looks up the word "java" on the</TT>
<BR><TT>// AltaVista search engine.</TT>
<BR><TT>page := getpage("http://www.altavista.digital.com/cgi-bin/query",</TT>
<BR><TT>&nbsp;&nbsp;&nbsp; [. pg="q", what="web", q="java" .])</TT></UL>
</UL>
&nbsp;&nbsp;&nbsp; <I>Sequential Execution</I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<TT>S ? T</TT>
<UL>The "?" combinator allows a secondary service to be consulted in the
case the primary service fails for some reason. Thus, the service <I>S
? T</I> acts like the service S except that if S fails then it executes
the service T.<p>

<UL><TT>// This program first attempts to connect to AltaVista</TT>
<BR><TT>// in California, and in the case of failure, attempts to</TT>
<BR><TT>// connect to a mirror in Australia</TT>
<BR><TT>page := getpage("http://www.altavista.digital.com") ?</TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getpage("http://www.altavi
sta.yellowpages.com.au")</TT></UL>
</UL>
&nbsp;&nbsp;&nbsp; <I>Concurrent Execution</I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<TT>S | T</TT>
<UL>The "|" combinator allows two services to be executed concurrently.
The service <I>S | T</I> starts both services S and T at the same time
and returns the result of whichever succeeds first. If both S and T fail,
then the combined service also fails.<p>

<UL><TT>// This program attempts to fetch a page from one of the two</TT>
<BR><TT>// alternate sites. Both sites are attempted concurrently, and
the</TT>
<BR><TT>// result is that from whichever site successfully completes first.</TT>
<BR><TT>page := getpage("http://www.altavista.digital.com") |</TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getpage("http://www.altavista.yellowpages.com.au")</TT></UL>
</UL>
&nbsp;&nbsp;&nbsp; <I>Time-out</I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<TT>timeout(t, S)</TT>
<UL>The time-out combinator allows a time limit to be placed on a service.
The service <I>timeout(t, S)</I> acts like S except that it fails after
t milliseconds if S has not completed within that time.<p>

<UL><TT>// This program attempts to connect to AltaVista, but</TT>
<BR><TT>// gives a limit of 10 seconds to succeed.</TT>
<BR><TT>page := timeout(10000, getpage("http://www.altavista ...") |</TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getpage("http://www.altavista... "))</TT></UL>
</UL>
&nbsp;&nbsp;&nbsp; <I>Repetition</I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<TT>repeat(S)</TT>
<UL>The repeat combinator provides a way to repeatedly invoke a service
until it succeeds. The service <I>repeat(S) </I>acts like S, except that
if S fails then S starts again. The loop can be terminated by writing <I>timeout(t,repeat(S))</I>.<p>

<UL><TT>// This program makes a repeated attempts in the</TT>
<BR><TT>// case of failure, alternating between two services.</TT>
<BR><TT>page := repeat(getpage("http://www.altavista ...") ?</TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
getpage("http://www.altavista ..."))</TT></UL>
</UL>
&nbsp;&nbsp;&nbsp; <I>Non-termination</I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<TT>stall()</TT>
<UL>The stall combinator never completes or fails.<p>
<UL><TT>// This program repeatedly tries to fetch the URL, but</TT>
<BR><TT>// waits 10 seconds between attempts.</TT>
<BR><TT>page := repeat(getpage("http://www.digital.com") ? timeout(10000,
stall())</TT></UL>
</UL>

<H2>4. Structured Text Search on Web Pages</H2>

<H3>4.1&nbsp; An Algebra for Text Search</H3>
One of the challenges in structured text search is to support a unified
model of different views of a document. In one view we are interested in
the linear text flow of the page (without tags), for example to locate
words and character patterns. In another view, we are interested in the
hierarchical organization of the document, for example to use markup as
"landmarks" for guiding data extraction. Other views, such as a publishers
view that divides the document into lines, paragraphs, and columns are
also imaginable. In addition, we observe that different views of the document
are not always properly nested, as are rows in tables, or words in titles.
Rather, different views might overlap. Sentences usually go across multiple
lines and images might span multiple columns. As a consequence, a unified
model has to allow searching on several views, mixing of query results
from different views, and handling of overlapping elements in the same
or different views.

<P>WebL's data extraction language addresses these problems with the notion
of a markup algebra. The <I>markup algebra</I> is based upon the concepts
of&nbsp; <I>pieces</I>, <I>piece-sets</I> and algebraic <I>operators</I>
that are applied to piece-sets.

<P>First, we define a <I>piece</I> as a contiguous text region in a document,
identified by the starting and the ending position of the region. For this
paper we can imagine positions as indices that indicate a character offset
in the page, which makes it easy to determine by numerical comparison the
relationship between two regions, such as whether two pieces overlap, are
contained in each other, or follow each other. The <I>length</I> of a piece
is defined as the difference between the starting and ending position.
(Our actual WebL implementation uses a more complicated data structure
for pieces that simplifies searching and page modification.) We further
define a <I>piece-set</I> as a collection of pieces. Pieces within piece-sets
may overlap, be nested, or may belong to different pages. However, unlike
mathematical sets that do not impose a particular ordering on their elements,
piece-sets are always in a canonical representation in which pieces are
ordered accordingly to their starting position, and then their ending position
in the document. This allows iterating over pieces in a set in the sequence
they appear in the document, and also to pick the n'th occurrence of a
pattern (by indexing into the piece-set). Both pieces and piece-sets are
mapped to special objects in WebL, which means that they can have attributes
and be manipulated by program.

<P>A common way to create a piece-set is to search for all the HTML or
XML elements with a specific name (we call this a <I>structured search</I>).
For example, the following program returns all the anchors (hyperlinks)
that occur on the DIGITAL homepage by calling a method called <I>Elem </I>of
the page object P:
<UL><TT>P := getpage("http://www.digital.com/");</TT>
<BR><TT>links := P.Elem("A")&nbsp;&nbsp; // returns a piece-set of "A"
elements</TT></UL>
After the method invocation, the variable <TT>links</TT> contains a piece-set
that, for every matching HTML or XML element, contains a piece that points
to the starting and ending position of the element. In addition, all the
element names and attributes are made visible to the programmer by associating
them with the appropriate piece object.

<P>Another way to create a piece-set is to search for character patterns,
ignoring the markup (we call this <I>unstructured search</I> or<I> pattern
search)</I>. The <I>Pat</I> method of a page object extracts all the occurrences
of a Perl 5-style regular expression [Fri97] in the text of a page. The
following example extracts the occurrences of the word "Digital" or "digital"
in the Digital home page.
<UL><TT>P := getpage("http://www.digital.com/");</TT>
<BR><TT>words := P.Pat("(D|d)igital")</TT></UL>
If the regular expression contains Perl-5 groups, the matching groups are
accessible as attributes of the piece. Like the Elem method, the Pat method
computes a set that, for every match, contains a piece that points to the
starting and ending position of the match.

<P>Finally, we define a <I>set operator S &curren; T
</I> as an algebraic operation &curren; between two
piece-sets S and T that returns a third piece-set as a result. For the
remainder of this section, <I>S </I>and <I>T</I> denote piece-sets, the
elements of <I>S</I> and <I>T</I> are referred to as <I>s</I> and <I>t</I>,
and <I>P</I> stands for a page object. WebL divides set operators into groups
of <I>basic set manipulation</I> operators, <I>positional</I> set operators, and
<I>hierarchical</I> set operators, which
will be discussed in the following sections. In the interest of conciseness,
we will not describe the negated operators (those starting with an exclamation
point), as their behavior is easy to deduce. 

<H3>4.2&nbsp; Basic set operators</H3>

<HR NOSHADE SIZE="1" WIDTH="30%" ALIGN="left">
<TABLE BORDER=0 WIDTH="30%" >
<TR>
<TD WIDTH="50%"><TT>Union</TT></TD>

<TD><TT>S + T</TT>&nbsp;</TD>
</TR>

<TR>
<TD WIDTH="50%"><TT>Intersection</TT></TD>

<TD><TT>S * T</TT>&nbsp;</TD>
</TR>

<TR>
<TD WIDTH="50%"><TT>Exclusion</TT></TD>

<TD><TT>S - T</TT>&nbsp;</TD>
</TR>
</TABLE>

<HR NOSHADE SIZE="1" WIDTH="30%" ALIGN="left">

<P>Basic set operators are used for basic set manipulation. They contain
a set union operator, a set intersection operator, and a set exclusion
operator. The set union operator merges the two sets S and T and eliminates
duplicate pieces. The set intersection operator returns the set of all
pieces that are contained both in S and T, and the set exclusion operator
calculates the set of pieces that are contained in S but not in T. As an
example, the following program retrieves all the level one and level two
headings in a page:
<UL><TT>titles := P.Elem("H1") + P.Elem("H2")</TT></UL>

<H3>
4.3&nbsp; Positional operators</H3>

<HR NOSHADE SIZE="1" WIDTH="50%" ALIGN="left">
<TABLE BORDER=0 WIDTH="50%" >
<TR>
<TD><TT>S before T</TT></TD>

<TD><TT>S !before T</TT>&nbsp;</TD>
</TR>

<TR>
<TD><TT>S after T</TT>&nbsp;</TD>

<TD><TT>S !after T</TT>&nbsp;</TD>
</TR>

<TR>
<TD><TT>S directlybefore T</TT>&nbsp;</TD>

<TD><TT>S !directlybefore T</TT>&nbsp;</TD>
</TR>

<TR>
<TD><TT>S directlyafter T</TT>&nbsp;</TD>

<TD><TT>S !directlyafter T</TT>&nbsp;</TD>
</TR>

<TR>
<TD><TT>S overlap T</TT>&nbsp;</TD>

<TD><TT>S !overlap T</TT>&nbsp;</TD>
</TR>
</TABLE>

<HR NOSHADE SIZE="1" WIDTH="50%" ALIGN="left">

<P>Positional operators provide functionality to query on the locality
property of pieces, such as searching for pieces that are located above
or below other pieces in the linear text flow of the document.

<P>The <TT>before</TT> operator computes the set of pieces in S that are
located before some piece in T. We define a piece s to be located before
a piece t, if the ending position of s precedes the starting position of
t. Correspondingly, the <TT>after operator</TT> returns the set of the
pieces in S that are located after some piece in T. Although being very
effective, these two operators are not always sufficient. As an example,
in some cases we might not be interested in all the occurrences of a link
after a special keyword, but only in the very first occurrence of a link
after the special keyword. In this case, we use the stronger operators
<TT>directlybefore</TT> and <TT>directlyafter</TT> that return the set
of only the closest pieces in S that follow or precede some piece in T. We
also call the latter non-transitive versions of the <TT>before</TT> and
<TT>after</TT> operator. The following example depicts the differences
between these operators:
<UL><TT>...</TT>
<BR><TT>&lt;IMG SRC="napa.gif"></TT>
<BR><TT>&lt;I>Fig 1. Sonoma and Napa&lt;/I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<I>// I1</I></TT>
<BR><TT>...</TT>
<BR><TT>&lt;IMG SRC="tahoe.gif"></TT>
<BR><TT>&lt;I>Fig 2. Lake Tahoe&lt;/I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<I>// I2</I></TT>
<BR><TT>...</TT>
<BR><TT>&lt;I>Northern California&lt;/I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<I>// I3</I></TT>
<BR><TT>...</TT>
<BR><TT>&lt;IMG SRC="mendocino.gif"></TT>
<BR><TT>&lt;I>Fig 3. Mendocino&lt;/I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <I>// I4</I></TT>
<BR><TT>...</TT></UL>
In order to retrieve the title of the first image we write the following
program, assuming that the first text stretch in italics in our excerpt
is also the first text stretch in italics in the whole document:
<UL><TT>// retrieve the first italic text stretch -> {I1}</TT>
<BR><TT>title := P.Elem("I")[0]</TT></UL>
Searching for all the words in italics that follow an image yields the
result set containing pieces I1, I2, I3, and I4.
<UL><TT>// retrieve all the titles that follow an image -> {I1, I2, I3,
I4}</TT>
<BR><TT>titles := P.Elem(I") after P.Elem("IMG")</TT></UL>
To retrieve all the titles of the figures we use the <TT>directlyafter</TT>
operator that does not return the word "Northern California", since it
does not directly follow an image.
<UL><TT>// retrieve all the titles of the figures -> {I1, I2, I4}</TT>
<BR><TT>titles := P.Elem("I") directlyafter P.Elem("IMG")</TT></UL>
Finally, the <TT>overlap</TT> operator returns all the pieces in S that
overlap with some piece in T.
<H3>
4.4&nbsp; Hierarchical operators</H3>

<HR NOSHADE SIZE="1" WIDTH="50%" ALIGN="left">
<TABLE BORDER=0 COLS=2 WIDTH="50%" BGCOLOR="#FFFFFF" >
<TR ALIGN=LEFT>
<TD ALIGN=LEFT><TT>S in T</TT></TD>

<TD ALIGN=LEFT><TT>S !in T</TT></TD>
</TR>

<TR>
<TD><TT>S contain T</TT>&nbsp;</TD>

<TD ALIGN=LEFT><TT>S !contain T</TT></TD>
</TR>

<TR>
<TD><TT>S directlyin T</TT>&nbsp;</TD>

<TD ALIGN=LEFT><TT>S !directlyin T</TT></TD>
</TR>

<TR>
<TD><TT>S directlycontain T</TT>&nbsp;</TD>

<TD ALIGN=LEFT><TT>S !directlycontain T</TT></TD>
</TR>
</TABLE>

<HR NOSHADE SIZE="1" WIDTH="50%" ALIGN="left">

<P>In contrast to positional operators that provide functionality to express
locality relationships between pieces, hierarchical operators provide functionality
to express containment and inclusion relationships between piece.

<P>The <TT>in</TT> operator returns the set of pieces in S that are contained
in some piece in T. We define a piece s to be contained in a piece t, if
the starting position of s follows or is equivalent to the starting position
of t, and the length of s is smaller or equal than the length of t. Equivalently,
the <TT>contain</TT> operator returns the set of pieces in S that contain
some piece in T. As an example, to search for all the rows in the third
table of a page, we write,

<P><TT>&nbsp;&nbsp;&nbsp; rows := P.Elem("TR") in P.Elem("TABLE")[2]</TT>

<P>and to search for all the level two headings that mention the word UCI
we write

<P><TT>&nbsp;&nbsp;&nbsp; titles := P.Elem("H2") contain P.Pat("UCI")</TT>

<P>As well as for positional operators, we define two stronger, non-transitive
operators <TT>directlyin</TT> and <TT>directlycontain</TT> that address
direct containment and direct inclusion properties. They return the set
of only the first pieces in S that contain or are contained in some piece
in T. The following example depicts the differences:
<UL><TT>&nbsp;&nbsp;&nbsp; ...</TT>
<BR><TT>&nbsp;&nbsp;&nbsp; &lt;UL></TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;LI>First Section&lt;/LI>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <I>// LI1</I></TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;LI>Second Section&lt;/LI>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp; <I>// LI2</I></TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;LI>Third Section&lt;/LI>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <I>// LI3</I></TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&lt;UL&gt;</TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp; &lt;LI>First Subsection&lt;/LI>&nbsp;&nbsp;&nbsp;
<I>// LI4</I></TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp; &lt;LI>Second Subsection&lt;/LI>&nbsp;&nbsp;
<I>// LI5</I></TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&lt;/UL&gt;</TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/LI></TT>
<BR><TT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;LI>Fourth Section&lt;/LI>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp; <I>// LI6</I></TT>
<BR><TT>&nbsp;&nbsp;&nbsp; &lt;/UL></TT>
<BR><TT>&nbsp;&nbsp;&nbsp; ...</TT></UL>
To retrieve all the list items in this unnumbered list, we write the following
program, assuming that there is no other unnumbered list preceding this
section in the document:

<P><TT>&nbsp;&nbsp;&nbsp; // retrieves all the subsections -> {LI1, LI2,
LI3, LI4, LI5, LI6}</TT>
<BR><TT>&nbsp;&nbsp;&nbsp; subsections := P.Elem("LI") in P.Elem("UL")[0]</TT>

<P>However, in many cases we are not interested in nested lists and would
only like to retrieve the list items of the top-level list. Therefore we
use the <TT>directlyin</TT> operator and write:

<P><TT>&nbsp;&nbsp;&nbsp; // retrieve only the toplevel subsections ->
{LI1, LI2, LI3, LI6}</TT>
<BR><TT>&nbsp;&nbsp;&nbsp; subsections := P.Elem("LI") directlyin P.Elem("UL")[0]</TT>

<H2>5. Related Work</H2>

Service combinators have first been presented by Cardelli and Davies in
[CD97]. Their semantics for service combinators differs slightly from the
WebL semantics in that their combinators include an extra<I> </I>combinator
<I>limit(t, r, S) </I>that acts like the service S, except that each connection
is considered to have failed if the rate ever drops below r Kbytes/sec
after the first t seconds of the connection. They can formally model the
status of a service at a particular time either by the current transfer
rate, the done status, or the fail status. The consequence of including the
transfer rate is that their service combinators can only operate on web services,
and not general computations. Ideally, we would like to make the service
combinators more orthogonal, so that a service and a computation on that
service can be expressed as a service itself. For example, a failure might
occur when a page was fetched successfully but the content of the page
is invalid or unexpected (as determined by a script that checks the page).
We obtain this orthogonality by removing the <I>limit</I> combinator, which
is not applicable to general computations (as they do not have a "rate").
Without the limit combinator, a computation's status is either <I>running</I>,
<I>completed</I>, or <I>failed</I>, and we can we map failure to
a programming exception. We can reintroduce the rate limit feature as part
of the <I>getpage</I> and <I>postpage</I> primitives themselves (for example
as separate arguments), which fail appropriately when the rate requirement
is not met.

<P>In practice, the most widely employed technique for searching in text
documents is pattern matching using <I>regular expressions</I> [Fri97,
IEEE92]. Regarding structured text search, the limitations of regular expressions
are twofold: they completely lack information about the structure of the
document and they apply a "leftmost longest match" rule which is often inappropriate
for nested data structures. Searching for a table, for example,
only returns a correct match if there is only one table in the document.
A discussion of this problem is found in [CC97].

<P>Several improved approaches to extracting information from semi-structured
text documents have recently been proposed. The most prominent techniques
are based on tree matching, grammar parsing, and set algebras.

<P>In <I>tree matching</I>, the search problem is reduced to searching
a subtree (i.e. pattern) in a parse-tree (i.e. view). The main disadvantage
of tree matching is the lack of orthogonality and compositionality regarding
different views (i.e. different parse trees). Queries that search for character
patterns cannot be mixed with searches for special structures in the document.
In addition, many of the tree matching problems cannot be solved in linear
time, but have polynomial runtime. Some problems (such as <i>unordered path inclusion</i>)
are even NP-complete [Kil92]. Several recent programming and searching
languages are based on tree matching, among them the programming language
<I>Turquois</I> [MM97]. 

<P><I>Context free grammars</I> pursue an approach, in which the search
pattern is specified as a context free grammar [ST96]. The result of a
search query are all the substrings in the document that are accepted by
the specified grammar. On the one hand, context free grammars are very
expressive in that they allow the definition of recursive search queries.
On the other hand, they suffer from the same problems as tree matching:
they do not allow expressing view-spanning and overlapping queries and
require polynomial runtime.

<P>Lately, several new techniques have been published that are based on
a set algebra [ST92, JK95, CCB94]. The <I>Standard
Document Query Language</I> (SDQL) of the <I>Document Style Semantics and
Specification Language</I> or DSSSL [DSSSL96] introduces the concept of
nodes and node-lists, which are loosely related to our pieces and piece-lists.
Some of the WebL operators are provided and the user can also program new
ones in a Lisp-like language. The data structure SDQL operates on &#150; called
a <I>grove</I> &#150; is essentially a tree of nodes corresponding to elements
in the document, and thus multiple views and overlapping elements cannot
be modelled. <I>PAT expressions</I> [ST92] use a set-at-a-time algebra
for manipulating sets of match-points and sets of regions. In contrast
to the WebL search algebra, PAT expressions do not support an orthogonal
and unified model. Sets of match-points and sets of regions cannot be arbitrarily
composed and, in regard to document transformation, match points are not
very practical since only the starting position of a match is recorded.
However, most of these problems can be avoided. Clarke, Cormack, and Burkowski
propose a compositional <I>structured text algebra</I> that is based on
the notion of sets and ranges [CCB94]. Apart from the WebL set-algebra,
this is the only other approach that supports overlappings between views.
Unfortunately, the idea has not completely been taken to the end. Although
the model supports overlappings the language does not (remember that WebL
has an explicit overlap operator). Additionally, nestings are avoided by
selecting the minimal segments from those set elements that nest. Concerning
runtime complexity, all of the set algebra problems can be solved in linear
time if no two elements in a set overlap [NY96]. In the worst case, if
all the elements in the set overlap with each other, the runtime complexity
is quadratic in the number of elements in the set. Considering the unlikelyness
of such an event and the importance of overlappings, this is a price that
we are willing to pay in WebL.

<P>In contrast to the above high-level search languages, their are also efforts
to specify low-level programming API's that provides users with
the functionality for document navigation and manipulation, such as navigating
through the document parse tree, or modifying HTML and XML elements. The
most prominent activity in this area is W3C's document object model [DOM97].
In contrast to WebL, DOM is restricted to manipulating and searching single
HTML and XML elements, it does not provide a notion of character patterns,
does not support multiple overlapping views, and inherently cannot perform
computation.

<P>There are also several recent proposals for automating tasks on the
web. The Web Interface Definition Language or WIDL [MA97] enables automation
by mapping web content into program variables using declarative descriptions
of resources. WIDL provides features to submit queries and to extract features
from the resulting pages. WIDL does not determine itself how search is
to be done, but rather uses the Java Page Object Model [JS] or the Document
Object Model [DOM97]. Page manipulation is not supported. WebSQL [AMM97]
is a declarative query language for extracting information from the web.
The language emphasis is on extracting connectivity information from pages
(for example to locate pages that are two hops away from a specific page).
WebSQL regards HTML documents as monolithic objects, and therefore its
analyses are limited to simple text matching techniques. The Internet Fish
Construction Kit (IFISH) is a tool to build dynamic information gatherers
on the web [LaM97]. Internet Fish use "info-chunks", possibly extracted
from web pages, or created by other independent fish, to place new info-chunks
on a shared black-board. The basic idea is that many fishes specialized
for specific tasks (for example looking for telephone numbers in a page)
make it easier to extract information from web pages that continually&nbsp;
change. IFISH is mainly concerned with the fish control structure and not
so much with the page fetching and data extracting steps.

<H2>6. Conclusions and Future Work</H2>

In this paper, we presented a novel programming language WebL for document
processing on the World-Wide-Web. WebL features two distinguishing features,
namely service combinators and a markup algebra. Service combinators allow
the construction of reliable services and the markup algebra supports the
extraction of data values from web pages. The language provides features
to perform computations on data values, and generate or manipulate web
pages appropriately. The resulting tool is well-suited for automating tasks
on the web and building and experimenting with web computations. We currently
plan to experiment with WebL for a while, to build larger applications
with it, and to extend it with additional libraries in the general domain
of information retrieval. One of the extensions we are currently investigating
is to generate WebL scripts automatically by demonstration. Another interesting
topic of investigation is how service combinators and the markup algebra
can be incorporated into the W3C's Document Object Model [DOM97].

<H2>References</H2>

<TABLE BORDER=0 CELLSPACING=2 CELLPADDING=0 >
<TR>
<TD VALIGN=TOP WIDTH="60">[AMM97]&nbsp;</TD>

<TD>Gustavo O. Arocena, Alberto O. Mendelzohn, and George A. Mihaila. <I>Applications
of a Web Query Language</I>. Proceedings of WWW6, 1997, Santa Clara, California.&nbsp;
<BR><A HREF="http://atlanta.cs.nchu.edu.tw/www/PAPER267.html">http://atlanta.cs.nchu.ed
u.tw/www/PAPER267.html</A>&nbsp;</TD>
</TR>


<TR>
<TD VALIGN=TOP WIDTH="60">[Car94]&nbsp;</TD>

<TD>Luca Cardelli. <I>Obliq: A language with distributed scope</I>. Research
Report 122, Digital Equipment Corporation Systems Research Center, Palo
Alto, California. June 1994.&nbsp;
<BR><A HREF="ftp://gatekeeper.dec.com/pub/DEC/SRC/research-reports/abstracts/src-rr-122.html">ftp://gatekeeper.dec.com/pub/DEC/SRC/research-reports/abstracts/src-rr-12
2.html</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[CC97]&nbsp;</TD>

<TD>C. L. A. Clarke and G. B. Cormack. <I>On the Use of Regular Expressions
for Searching Text</I>. ACM Transactions on Programming Languages and Systems,
19(3), pp 413-426. March 1997.&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[CCB94]&nbsp;</TD>

<TD>C. L. A. Clarke, G. V. Cormack, and F. J. Burkowski. <I>An Algebra
for Structured Text Search and a Framework for its Implementation</I>.
Department of Computer Science, University of Waterloo, Canada, Technical
Report CS-94-30. August 1994.</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[CD97]&nbsp;</TD>

<TD>Luca Cardelli and Rowan Davies. <I>Service combinators for Web Computing</I>.
Research Report 148, Digital Equipment Corporation Systems Research Center,
Palo Alto, California. June 1997.&nbsp;
<BR><A HREF="ftp://gatekeeper.dec.com/pub/DEC/SRC/research-reports/abstracts/src-rr-148.html">ftp://gatekeeper.dec.com/pub/DEC/SRC/research-reports/abstracts/src-rr-14
8.html</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[CDF97]&nbsp;</TD>

<TD>Channel Definition Format (CDF). Published by Microsoft Corp. September,
1997.&nbsp;
<BR><A HREF="http://www.microsoft.com/standards/cdf.htm">http://www.microsoft.com/stand
ards/cdf.htm</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[DOM97]&nbsp;</TD>

<TD>W3C DOM working group. <I>Document Object Model Specification</I>.
October 1997.&nbsp;
<BR><A HREF="http://www.w3.org/TR/WD-DOM/">http://www.w3.org/TR/WD-DOM/</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[DSSL96]&nbsp;</TD>

<TD><I>Document Style Semantics and Specification Language (DSSSL)</I>,
ISO/IEC 10179:1996.&nbsp;
<BR><A HREF="http://www.jclark.com/dsssl/">http://www.jclark.com/dsssl/</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[Fri97]&nbsp;</TD>

<TD>Jeffrey E. F. Friedl. <I>Mastering Regular Expressions: Powerful Techniques
for Perl and Other Tools (Nutshell Handbook)</I>.&nbsp; O'Reilly and Associates,
1997&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[IEEE92]&nbsp;</TD>

<TD>IEEE 1992. <I>Standard for information technology - Portable Operating
System Interface (POSIX) - Part 2(Shell and utilities) - Section 2.8 (Regular
expression notation)</I>. IEEE Std 1003.2, Institute of Electrical and
Electronics Engineers, New York 1992.&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[JK95]&nbsp;</TD>

<TD>J. Jaakkola and P. Kilpelainen. <I>SGREP</I>. University of Helsinki,
Department of Computer Science, 1995.&nbsp;
<BR><A HREF="http://www.cs.helsinki.fi/~jjaakkol/sgrep.html">http://www.cs.helsinki.fi/
~jjaakkol/sgrep.html</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[JS]&nbsp;</TD>

<TD>Netscape Corp. <I>JavaScript Guide</I>.&nbsp;
<BR><A HREF="http://developer.netscape.com/library/documentation/communicator/jsguide4/index.htm">http://developer.netscape.com/library/documentation/communicator/jsgu
ide4/index.htm</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[Kil92]&nbsp;</TD>

<TD>P. Kilpelainen. <I>Tree Matching Problems with Applications to Structured
Text Databases.</I> Ph. D. Dissertation, Department of Computer Science,
University of Helsinki, Report A-19992-6, Helsinki, Finland. November 1992.&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[LaM97]&nbsp;</TD>

<TD>Brian A. LaMacchia. <I>The Internet Fish Construction Kit</I>. Proceedings
of WWW6, 1997, Santa Clara, California.&nbsp;
<BR><A HREF="http://atlanta.cs.nchu.edu.tw/www/PAPER138.html">http://atlanta.cs.nchu.ed
u.tw/www/PAPER138.html</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[MA97]&nbsp;</TD>

<TD>Phillip Merrick, Charles Allen. <I>Web Interface Definition Language
(WIDL)</I>. Published by webMethods Inc. September 1997.&nbsp;
<BR><A HREF="http://www.w3.org/TR/NOTE-widl">http://www.w3.org/TR/NOTE-widl</A>&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[MM97]&nbsp;</TD>

<TD>R. C. Miller and B. A. Myers. <I>Creating Dynamic World Wide Web Pages
By Demonstration</I>. Carnegie Mellon University School of Computer Science
Tech Report CMU-CS-97-131. May 1997.&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[NY96]&nbsp;</TD>

<TD>G. Navarro and R. Baeza-Yates. <I>A Class of Linear Algorithms to Process
Sets of Segments</I>. In Proceedings of PANEL'96, Volume 2, pp. 671-682,
1996&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[ST92]&nbsp;</TD>

<TD>A. Salminen and F. W. Tompa. <I>PAT expressions: an algebra for text
search</I>. Acta Linguistica Hungarica, Vol. 41 (1-4), pp. 277-306, 1992-93.&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[ST96]&nbsp;</TD>

<TD>A. Salminen and F. W. Tompa. <I>Grammars++ for Modelling Information
in Text</I>. Department of Computer Science, University of Waterloo, Canada,
Technical Report, CS-96-40. November 1996.&nbsp;</TD>
</TR>

<TR>
<TD VALIGN=TOP WIDTH="60">[Wir82]&nbsp;</TD>

<TD>Niklaus Wirth. <I>Programming in Modula-2</I> (Texts and Monographs
in Computer Science). Springer Verlag, 1982.</TD>
</TR>
</TABLE>


<H2>Appendix</H2>
Although we can't give a full description of WebL in this paper, we can
give a flavor of the language itself. <I>Listing 1</I> implements a simple
function to retrieve a stock quotation from a service. <I>Listing 2</I>
implements a more complicated&nbsp; function to search for books by title
or author at the electronic book store <I>Amazon.com</I>. It fills in the
query form, analyses the results, and returns a list of book objects for
each book found.

<P>&nbsp;

<center><IMG SRC="quote.gif" HEIGHT=167 WIDTH=526></center>
<PRE>
&nbsp;&nbsp; stockQuote := fun(symbol)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page := getpage("http://fast.quote.com/fq/quotecom/quote", [. symbols=symbol .]);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (page.Elem("B") in (page.Elem("TABLE") contain page.Pat("Stock Quotes"))[0])[1].Text()
&nbsp;&nbsp; end;

&nbsp;&nbsp; s := stockQuote("DEC")</PRE>

<CENTER><I>Listing 1.</I> Retrieving a stock price from Quote.com</CENTER>
<br><br>


<center><IMG SRC="amazon.gif" HEIGHT=231 WIDTH=403></center>
<pre>
&nbsp;&nbsp; shopAmazon := fun(title, authorfirst, authorlast)
&nbsp;&nbsp;&nbsp;&nbsp; books := [];
&nbsp;&nbsp;&nbsp;&nbsp; params := [. .];
&nbsp;&nbsp;&nbsp;&nbsp; params["author"] := authorfirst + " " + authorlast;
&nbsp;&nbsp;&nbsp;&nbsp; params["author-mode"] := "full";
&nbsp;&nbsp;&nbsp;&nbsp; params["title"] := title;
&nbsp;&nbsp;&nbsp;&nbsp; params["title-mode"] := "word";
&nbsp;&nbsp;&nbsp;&nbsp; params["subject"] := "";
&nbsp;&nbsp;&nbsp;&nbsp; params["subject-mode"] := "word";
&nbsp;&nbsp;&nbsp;&nbsp; page := postpage("http://www.amazon.com/exec/obidos/ats-query/", params);&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp; items := page.Elem("dd");
&nbsp;&nbsp;&nbsp;&nbsp; every book in items do
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; info1 := substring(book.Text(), `\w*([^/]*) (/ ([^/]*))?(/ [^\d]*(\d*))?`)[0];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; info2 := substring(book.Text(), `Our Price: \$(\d*.\d*)`);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (size(info2) > 0) and (info1[3] != "Audio Cassette") then
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; books = books + [[.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; title = (page.Elem("a") directlybefore book)[0].Text(),
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; link = (page.Elem("a") directlybefore book)[0].href,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; author = info1[1],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; type = info1[3],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; year = (select(info1[5],-2,-1) ? "N/A"),
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; price = info2[0][1]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; .]]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; end
&nbsp;&nbsp;&nbsp;&nbsp; end;
&nbsp;&nbsp;&nbsp;&nbsp; books
&nbsp;&nbsp; end</PRE>

<CENTER><I>Listing 2.</I>&nbsp; A WebL function to shop for books</CENTER>

</BODY>
</HTML>
